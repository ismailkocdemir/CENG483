{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from network import *\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "\n",
    "learning_rates =[1e-2, 1e-4,  1e-7 ]\n",
    "momentum = [0, 0.5, 0.9 ]\n",
    "regul = [1e-1,1e-3,1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.01 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 95\n",
      "Training finished. Best val acc: 0.593\n",
      "=========================================\n",
      "LR: 0.01 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 86\n",
      "Training finished. Best val acc: 0.589\n",
      "=========================================\n",
      "LR: 0.01 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 101\n",
      "Training finished. Best val acc: 0.589\n",
      "=========================================\n",
      "LR: 0.01 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 81\n",
      "Training finished. Best val acc: 0.5925\n",
      "=========================================\n",
      "LR: 0.01 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 77\n",
      "Training finished. Best val acc: 0.5885\n",
      "=========================================\n",
      "LR: 0.01 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 62\n",
      "Training finished. Best val acc: 0.5920000000000001\n",
      "=========================================\n",
      "LR: 0.01 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 61\n",
      "Training finished. Best val acc: 0.5880000000000001\n",
      "=========================================\n",
      "LR: 0.01 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 85\n",
      "Training finished. Best val acc: 0.5905\n",
      "=========================================\n",
      "LR: 0.01 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 100\n",
      "Training finished. Best val acc: 0.5905\n",
      "=========================================\n",
      "LR: 0.0001 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 73\n",
      "Training finished. Best val acc: 0.5880000000000001\n",
      "=========================================\n",
      "LR: 0.0001 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 132\n",
      "Training finished. Best val acc: 0.5905\n",
      "=========================================\n",
      "LR: 0.0001 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 101\n",
      "Training finished. Best val acc: 0.5885\n",
      "=========================================\n",
      "LR: 0.0001 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 63\n",
      "Training finished. Best val acc: 0.5865\n",
      "=========================================\n",
      "LR: 0.0001 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 99\n",
      "Training finished. Best val acc: 0.5915\n",
      "=========================================\n",
      "LR: 0.0001 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 96\n",
      "Training finished. Best val acc: 0.589\n",
      "=========================================\n",
      "LR: 0.0001 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 65\n",
      "Training finished. Best val acc: 0.5915\n",
      "=========================================\n",
      "LR: 0.0001 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 67\n",
      "Training finished. Best val acc: 0.589\n",
      "=========================================\n",
      "LR: 0.0001 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 68\n",
      "Training finished. Best val acc: 0.5915\n",
      "=========================================\n",
      "LR: 1e-07 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 97\n",
      "Training finished. Best val acc: 0.5900000000000001\n",
      "=========================================\n",
      "LR: 1e-07 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 86\n",
      "Training finished. Best val acc: 0.5895\n",
      "=========================================\n",
      "LR: 1e-07 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 111\n",
      "Training finished. Best val acc: 0.5880000000000001\n",
      "=========================================\n",
      "LR: 1e-07 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 78\n",
      "Training finished. Best val acc: 0.5905\n",
      "=========================================\n",
      "LR: 1e-07 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 77\n",
      "Training finished. Best val acc: 0.591\n",
      "=========================================\n",
      "LR: 1e-07 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 120\n",
      "Training finished. Best val acc: 0.5900000000000001\n",
      "=========================================\n",
      "LR: 1e-07 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 92\n",
      "Training finished. Best val acc: 0.5895\n",
      "=========================================\n",
      "LR: 1e-07 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 98\n",
      "Training finished. Best val acc: 0.5895\n",
      "=========================================\n",
      "LR: 1e-07 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 66\n",
      "Training finished. Best val acc: 0.5880000000000001\n",
      "=========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f057c134a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "best_val_acc = 0.0\n",
    "best_settings = {}\n",
    "best_zero_model = None\n",
    "i=0\n",
    "for lr in learning_rates:\n",
    "    for mom in momentum:\n",
    "        for rg in regul:\n",
    "            print(\"LR:\", lr, \"MOM:\", mom, \"REG:\", rg)\n",
    "            zero_model = FCNetwork(hidden_sizes=[])\n",
    "            trained_model,best_val,tr_hist,val_hist = trainer.train(zero_model, verbose=False, num_epochs=1000,\\\n",
    "                                                   lr=lr, weight_decay=regul, momentum=mom, batch_size=64)\n",
    "            \n",
    "            epochs=np.arange(len(tr_hist))\n",
    "            tr_hist = [min(tr_hist[i],700.0) for i in range(len(epochs))]\n",
    "            val_hist = [min(val_hist[i],700.0) for i in range(len(epochs))]\n",
    "            plt.plot(epochs, tr_hist, label=\"training error\")\n",
    "            plt.plot(epochs, val_hist, label=\"validation error\")\n",
    "            plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "                       ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "            plt.savefig(\"zero_LR={0:.1E}_MOM={1:.1E}_REG={2:.1E}.png\".format(lr, mom, rg))\n",
    "            plt.clf()\n",
    "            \n",
    "            if best_val > best_val_acc:\n",
    "                best_val_acc = best_val\n",
    "                best_zero_model = trained_model\n",
    "                best_settings.update( { \"LR\":lr, \"MOM\": mom, \"REG\": rg } )\n",
    "                torch.save(trained_model,\"zero_LR={0:.1E}_MOM={1:.1E}_REG={2:.1E}.pt\".format(lr,mom,rg))\n",
    "            print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, out = trainer.evaluate(best_zero_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_settings: {'LR': 0.01, 'MOM': 0, 'REG': 0.1}\n",
      "best accuracy for zero hidden layer: 0.593\n"
     ]
    }
   ],
   "source": [
    "print(\"best_settings:\", best_settings)\n",
    "print(\"best accuracy for zero hidden layer:\",acc)\n",
    "np.save( \"best_zero_estimations.npy\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HID: [512] LR: 0.01 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 91\n",
      "Training finished. Best val acc: 0.629\n",
      "=========================================\n",
      "HID: [512] LR: 0.01 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 67\n",
      "Training finished. Best val acc: 0.6295\n",
      "=========================================\n",
      "HID: [512] LR: 0.01 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 62\n",
      "Training finished. Best val acc: 0.6194999999999999\n",
      "=========================================\n",
      "HID: [512] LR: 0.01 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 58\n",
      "Training finished. Best val acc: 0.6234999999999999\n",
      "=========================================\n",
      "HID: [512] LR: 0.01 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 62\n",
      "Training finished. Best val acc: 0.6325000000000001\n",
      "=========================================\n",
      "HID: [512] LR: 0.01 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 70\n",
      "Training finished. Best val acc: 0.6375\n",
      "=========================================\n",
      "HID: [512] LR: 0.01 MOM: 0.7 REG: 0.1\n",
      "Early stopping at epoch: 49\n",
      "Training finished. Best val acc: 0.6205\n",
      "=========================================\n",
      "HID: [512] LR: 0.01 MOM: 0.7 REG: 0.001\n",
      "Early stopping at epoch: 66\n",
      "Training finished. Best val acc: 0.6214999999999999\n",
      "=========================================\n",
      "HID: [512] LR: 0.01 MOM: 0.7 REG: 1e-05\n",
      "Early stopping at epoch: 71\n",
      "Training finished. Best val acc: 0.624\n",
      "=========================================\n",
      "HID: [512] LR: 0.01 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 70\n",
      "Training finished. Best val acc: 0.633\n",
      "=========================================\n",
      "HID: [512] LR: 0.01 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 80\n",
      "Training finished. Best val acc: 0.641\n",
      "=========================================\n",
      "HID: [512] LR: 0.01 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 49\n",
      "Training finished. Best val acc: 0.6315\n",
      "=========================================\n",
      "HID: [512] LR: 0.0001 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 63\n",
      "Training finished. Best val acc: 0.6315\n",
      "=========================================\n",
      "HID: [512] LR: 0.0001 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 59\n",
      "Training finished. Best val acc: 0.6335\n",
      "=========================================\n",
      "HID: [512] LR: 0.0001 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 73\n",
      "Training finished. Best val acc: 0.643\n",
      "=========================================\n",
      "HID: [512] LR: 0.0001 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 46\n",
      "Training finished. Best val acc: 0.627\n",
      "=========================================\n",
      "HID: [512] LR: 0.0001 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 94\n",
      "Training finished. Best val acc: 0.6285000000000001\n",
      "=========================================\n",
      "HID: [512] LR: 0.0001 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 72\n",
      "Training finished. Best val acc: 0.6325000000000001\n",
      "=========================================\n",
      "HID: [512] LR: 0.0001 MOM: 0.7 REG: 0.1\n",
      "Early stopping at epoch: 70\n",
      "Training finished. Best val acc: 0.6185\n",
      "=========================================\n",
      "HID: [512] LR: 0.0001 MOM: 0.7 REG: 0.001\n",
      "Early stopping at epoch: 89\n",
      "Training finished. Best val acc: 0.6305000000000001\n",
      "=========================================\n",
      "HID: [512] LR: 0.0001 MOM: 0.7 REG: 1e-05\n",
      "Early stopping at epoch: 65\n",
      "Training finished. Best val acc: 0.62\n",
      "=========================================\n",
      "HID: [512] LR: 0.0001 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 70\n",
      "Training finished. Best val acc: 0.634\n",
      "=========================================\n",
      "HID: [512] LR: 0.0001 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 62\n",
      "Training finished. Best val acc: 0.6214999999999999\n",
      "=========================================\n",
      "HID: [512] LR: 0.0001 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 72\n",
      "Training finished. Best val acc: 0.63\n",
      "=========================================\n",
      "HID: [512] LR: 1e-07 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 87\n",
      "Training finished. Best val acc: 0.6325000000000001\n",
      "=========================================\n",
      "HID: [512] LR: 1e-07 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 55\n",
      "Training finished. Best val acc: 0.624\n",
      "=========================================\n",
      "HID: [512] LR: 1e-07 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 64\n",
      "Training finished. Best val acc: 0.632\n",
      "=========================================\n",
      "HID: [512] LR: 1e-07 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 61\n",
      "Training finished. Best val acc: 0.6335\n",
      "=========================================\n",
      "HID: [512] LR: 1e-07 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 76\n",
      "Training finished. Best val acc: 0.622\n",
      "=========================================\n",
      "HID: [512] LR: 1e-07 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 75\n",
      "Training finished. Best val acc: 0.635\n",
      "=========================================\n",
      "HID: [512] LR: 1e-07 MOM: 0.7 REG: 0.1\n",
      "Early stopping at epoch: 64\n",
      "Training finished. Best val acc: 0.6325000000000001\n",
      "=========================================\n",
      "HID: [512] LR: 1e-07 MOM: 0.7 REG: 0.001\n",
      "Early stopping at epoch: 59\n",
      "Training finished. Best val acc: 0.6275\n",
      "=========================================\n",
      "HID: [512] LR: 1e-07 MOM: 0.7 REG: 1e-05\n",
      "Early stopping at epoch: 60\n",
      "Training finished. Best val acc: 0.6265000000000001\n",
      "=========================================\n",
      "HID: [512] LR: 1e-07 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 92\n",
      "Training finished. Best val acc: 0.627\n",
      "=========================================\n",
      "HID: [512] LR: 1e-07 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 83\n",
      "Training finished. Best val acc: 0.6275\n",
      "=========================================\n",
      "HID: [512] LR: 1e-07 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 72\n",
      "Training finished. Best val acc: 0.6305000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 0.01 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 69\n",
      "Training finished. Best val acc: 0.6415\n",
      "=========================================\n",
      "HID: [1024] LR: 0.01 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 91\n",
      "Training finished. Best val acc: 0.6365000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 0.01 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 74\n",
      "Training finished. Best val acc: 0.6285000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 0.01 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 65\n",
      "Training finished. Best val acc: 0.6315\n",
      "=========================================\n",
      "HID: [1024] LR: 0.01 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 64\n",
      "Training finished. Best val acc: 0.633\n",
      "=========================================\n",
      "HID: [1024] LR: 0.01 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 65\n",
      "Training finished. Best val acc: 0.6234999999999999\n",
      "=========================================\n",
      "HID: [1024] LR: 0.01 MOM: 0.7 REG: 0.1\n",
      "Early stopping at epoch: 59\n",
      "Training finished. Best val acc: 0.6275\n",
      "=========================================\n",
      "HID: [1024] LR: 0.01 MOM: 0.7 REG: 0.001\n",
      "Early stopping at epoch: 58\n",
      "Training finished. Best val acc: 0.6355\n",
      "=========================================\n",
      "HID: [1024] LR: 0.01 MOM: 0.7 REG: 1e-05\n",
      "Early stopping at epoch: 56\n",
      "Training finished. Best val acc: 0.6365000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 0.01 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 82\n",
      "Training finished. Best val acc: 0.6305000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 0.01 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 61\n",
      "Training finished. Best val acc: 0.638\n",
      "=========================================\n",
      "HID: [1024] LR: 0.01 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 60\n",
      "Training finished. Best val acc: 0.63\n",
      "=========================================\n",
      "HID: [1024] LR: 0.0001 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 70\n",
      "Training finished. Best val acc: 0.635\n",
      "=========================================\n",
      "HID: [1024] LR: 0.0001 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 67\n",
      "Training finished. Best val acc: 0.6315\n",
      "=========================================\n",
      "HID: [1024] LR: 0.0001 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 58\n",
      "Training finished. Best val acc: 0.628\n",
      "=========================================\n",
      "HID: [1024] LR: 0.0001 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 57\n",
      "Training finished. Best val acc: 0.627\n",
      "=========================================\n",
      "HID: [1024] LR: 0.0001 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 60\n",
      "Training finished. Best val acc: 0.6285000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 0.0001 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 61\n",
      "Training finished. Best val acc: 0.6265000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 0.0001 MOM: 0.7 REG: 0.1\n",
      "Early stopping at epoch: 59\n",
      "Training finished. Best val acc: 0.641\n",
      "=========================================\n",
      "HID: [1024] LR: 0.0001 MOM: 0.7 REG: 0.001\n",
      "Early stopping at epoch: 64\n",
      "Training finished. Best val acc: 0.6305000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 0.0001 MOM: 0.7 REG: 1e-05\n",
      "Early stopping at epoch: 89\n",
      "Training finished. Best val acc: 0.6245\n",
      "=========================================\n",
      "HID: [1024] LR: 0.0001 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 63\n",
      "Training finished. Best val acc: 0.641\n",
      "=========================================\n",
      "HID: [1024] LR: 0.0001 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 85\n",
      "Training finished. Best val acc: 0.6275\n",
      "=========================================\n",
      "HID: [1024] LR: 0.0001 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 74\n",
      "Training finished. Best val acc: 0.6355\n",
      "=========================================\n",
      "HID: [1024] LR: 1e-07 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 78\n",
      "Training finished. Best val acc: 0.6345000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 1e-07 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 63\n",
      "Training finished. Best val acc: 0.64\n",
      "=========================================\n",
      "HID: [1024] LR: 1e-07 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 67\n",
      "Training finished. Best val acc: 0.631\n",
      "=========================================\n",
      "HID: [1024] LR: 1e-07 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 83\n",
      "Training finished. Best val acc: 0.6445000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 1e-07 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 69\n",
      "Training finished. Best val acc: 0.6325000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 1e-07 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 53\n",
      "Training finished. Best val acc: 0.6255\n",
      "=========================================\n",
      "HID: [1024] LR: 1e-07 MOM: 0.7 REG: 0.1\n",
      "Early stopping at epoch: 71\n",
      "Training finished. Best val acc: 0.6305000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 1e-07 MOM: 0.7 REG: 0.001\n",
      "Early stopping at epoch: 70\n",
      "Training finished. Best val acc: 0.633\n",
      "=========================================\n",
      "HID: [1024] LR: 1e-07 MOM: 0.7 REG: 1e-05\n",
      "Early stopping at epoch: 62\n",
      "Training finished. Best val acc: 0.623\n",
      "=========================================\n",
      "HID: [1024] LR: 1e-07 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 75\n",
      "Training finished. Best val acc: 0.6365000000000001\n",
      "=========================================\n",
      "HID: [1024] LR: 1e-07 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 58\n",
      "Training finished. Best val acc: 0.6315\n",
      "=========================================\n",
      "HID: [1024] LR: 1e-07 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 82\n",
      "Training finished. Best val acc: 0.6365000000000001\n",
      "=========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0575b2dac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_dims = [ [512],[1024]]\n",
    "learning_rates =[1e-2, 1e-4,  1e-7 ]\n",
    "momentum =[0, 0.5, 0.7, 0.9 ]\n",
    "regul =[1e-1,1e-3,1e-5]\n",
    "best_val_acc = 0.0\n",
    "best_one_model = None\n",
    "best_settings = {}\n",
    "\n",
    "for hd in hidden_dims:\n",
    "    for lr in learning_rates:\n",
    "        for mom in momentum:\n",
    "            for rg in regul:\n",
    "                print(\"HID:\",hd, \"LR:\", lr, \"MOM:\", mom, \"REG:\", rg)\n",
    "                one_model = FCNetwork(hidden_sizes=hd)\n",
    "                trained_model,best_val,tr_hist,val_hist = trainer.train(one_model, verbose=False, num_epochs=1000,\\\n",
    "                                                lr=lr, weight_decay=regul, momentum=mom, batch_size=64)\n",
    "\n",
    "                epochs=np.arange(len(tr_hist))\n",
    "                tr_hist = [min(tr_hist[i],700.0) for i in range(len(epochs))]\n",
    "                val_hist = [min(val_hist[i],700.0) for i in range(len(epochs))]\n",
    "                plt.plot(epochs, tr_hist, label=\"training error\")\n",
    "                plt.plot(epochs, val_hist, label=\"validation error\")\n",
    "                plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "                           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "                plt.savefig(\"HID:{0:}_LR={1:.1E}_MOM={2:.1E}_REG={3:.1E}.png\".format(str(hd),lr, mom, rg))\n",
    "                plt.clf()\n",
    "\n",
    "                if best_val > best_val_acc:\n",
    "                    best_val_acc = best_val\n",
    "                    best_one_model = trained_model\n",
    "                    best_settings.update( {\"HID\":hd, \"LR\":lr, \"MOM\": mom, \"REG\": rg } )\n",
    "                    torch.save(trained_model,\"HID:{0}_LR={1:.1E}_MOM={2:.1E}_REG={3:.1E}.pt\".format(str(hd),lr,mom,rg))\n",
    "                print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6445000000000001\n"
     ]
    }
   ],
   "source": [
    "acc, out=trainer.evaluate(best_one_model)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_settings: {'HID': [1024], 'LR': 1e-07, 'MOM': 0.5, 'REG': 0.1}\n",
      "best accuracy for one hidden layer: 0.6445000000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"best_settings:\", best_settings)\n",
    "print(\"best accuracy for one hidden layer:\",acc)\n",
    "np.save( \"best_one_estimations.npy\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HID: [512, 256] LR: 0.01 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 77\n",
      "Training finished. Best val acc: 0.628\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.01 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 48\n",
      "Training finished. Best val acc: 0.6265000000000001\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.01 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 131\n",
      "Training finished. Best val acc: 0.6405000000000001\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.01 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 153\n",
      "Training finished. Best val acc: 0.639\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.01 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 109\n",
      "Training finished. Best val acc: 0.64\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.01 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 76\n",
      "Training finished. Best val acc: 0.624\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.01 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 71\n",
      "Training finished. Best val acc: 0.633\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.01 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 58\n",
      "Training finished. Best val acc: 0.637\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.01 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 73\n",
      "Training finished. Best val acc: 0.634\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.0001 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 47\n",
      "Training finished. Best val acc: 0.6295\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.0001 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 101\n",
      "Training finished. Best val acc: 0.638\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.0001 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 67\n",
      "Training finished. Best val acc: 0.625\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.0001 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 80\n",
      "Training finished. Best val acc: 0.6325000000000001\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.0001 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 82\n",
      "Training finished. Best val acc: 0.63\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.0001 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 70\n",
      "Training finished. Best val acc: 0.6365000000000001\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.0001 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 132\n",
      "Training finished. Best val acc: 0.638\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.0001 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 67\n",
      "Training finished. Best val acc: 0.6375\n",
      "=========================================\n",
      "HID: [512, 256] LR: 0.0001 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 47\n",
      "Training finished. Best val acc: 0.632\n",
      "=========================================\n",
      "HID: [512, 256] LR: 1e-07 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 75\n",
      "Training finished. Best val acc: 0.637\n",
      "=========================================\n",
      "HID: [512, 256] LR: 1e-07 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 93\n",
      "Training finished. Best val acc: 0.6335\n",
      "=========================================\n",
      "HID: [512, 256] LR: 1e-07 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 90\n",
      "Training finished. Best val acc: 0.632\n",
      "=========================================\n",
      "HID: [512, 256] LR: 1e-07 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 80\n",
      "Training finished. Best val acc: 0.6194999999999999\n",
      "=========================================\n",
      "HID: [512, 256] LR: 1e-07 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 72\n",
      "Training finished. Best val acc: 0.626\n",
      "=========================================\n",
      "HID: [512, 256] LR: 1e-07 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 70\n",
      "Training finished. Best val acc: 0.633\n",
      "=========================================\n",
      "HID: [512, 256] LR: 1e-07 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 87\n",
      "Training finished. Best val acc: 0.631\n",
      "=========================================\n",
      "HID: [512, 256] LR: 1e-07 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 63\n",
      "Training finished. Best val acc: 0.6275\n",
      "=========================================\n",
      "HID: [512, 256] LR: 1e-07 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 71\n",
      "Training finished. Best val acc: 0.63\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.01 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 136\n",
      "Training finished. Best val acc: 0.632\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.01 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 46\n",
      "Training finished. Best val acc: 0.6325000000000001\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.01 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 134\n",
      "Training finished. Best val acc: 0.637\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.01 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 122\n",
      "Training finished. Best val acc: 0.63\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.01 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 86\n",
      "Training finished. Best val acc: 0.6275\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.01 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 135\n",
      "Training finished. Best val acc: 0.6385000000000001\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.01 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 85\n",
      "Training finished. Best val acc: 0.6345000000000001\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.01 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 111\n",
      "Training finished. Best val acc: 0.6385000000000001\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.01 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 114\n",
      "Training finished. Best val acc: 0.634\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.0001 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 103\n",
      "Training finished. Best val acc: 0.638\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.0001 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 113\n",
      "Training finished. Best val acc: 0.6425000000000001\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.0001 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 87\n",
      "Training finished. Best val acc: 0.633\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.0001 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 101\n",
      "Training finished. Best val acc: 0.644\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.0001 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 100\n",
      "Training finished. Best val acc: 0.639\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.0001 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 96\n",
      "Training finished. Best val acc: 0.6355\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.0001 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 89\n",
      "Training finished. Best val acc: 0.635\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.0001 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 64\n",
      "Training finished. Best val acc: 0.6375\n",
      "=========================================\n",
      "HID: [512, 512] LR: 0.0001 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 43\n",
      "Training finished. Best val acc: 0.624\n",
      "=========================================\n",
      "HID: [512, 512] LR: 1e-07 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 132\n",
      "Training finished. Best val acc: 0.6425000000000001\n",
      "=========================================\n",
      "HID: [512, 512] LR: 1e-07 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 54\n",
      "Training finished. Best val acc: 0.6194999999999999\n",
      "=========================================\n",
      "HID: [512, 512] LR: 1e-07 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 89\n",
      "Training finished. Best val acc: 0.6415\n",
      "=========================================\n",
      "HID: [512, 512] LR: 1e-07 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 106\n",
      "Training finished. Best val acc: 0.646\n",
      "=========================================\n",
      "HID: [512, 512] LR: 1e-07 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 44\n",
      "Training finished. Best val acc: 0.6185\n",
      "=========================================\n",
      "HID: [512, 512] LR: 1e-07 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 144\n",
      "Training finished. Best val acc: 0.6435\n",
      "=========================================\n",
      "HID: [512, 512] LR: 1e-07 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 81\n",
      "Training finished. Best val acc: 0.627\n",
      "=========================================\n",
      "HID: [512, 512] LR: 1e-07 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 46\n",
      "Training finished. Best val acc: 0.626\n",
      "=========================================\n",
      "HID: [512, 512] LR: 1e-07 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 125\n",
      "Training finished. Best val acc: 0.6365000000000001\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.01 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 69\n",
      "Training finished. Best val acc: 0.633\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.01 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 75\n",
      "Training finished. Best val acc: 0.6275\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.01 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 90\n",
      "Training finished. Best val acc: 0.636\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.01 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 98\n",
      "Training finished. Best val acc: 0.639\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.01 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 90\n",
      "Training finished. Best val acc: 0.6385000000000001\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.01 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 73\n",
      "Training finished. Best val acc: 0.633\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.01 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 67\n",
      "Training finished. Best val acc: 0.635\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.01 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 72\n",
      "Training finished. Best val acc: 0.6445000000000001\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.01 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 81\n",
      "Training finished. Best val acc: 0.636\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.0001 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 68\n",
      "Training finished. Best val acc: 0.6425000000000001\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.0001 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 81\n",
      "Training finished. Best val acc: 0.6425000000000001\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.0001 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 80\n",
      "Training finished. Best val acc: 0.639\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.0001 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 85\n",
      "Training finished. Best val acc: 0.6335\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.0001 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 75\n",
      "Training finished. Best val acc: 0.635\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.0001 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 64\n",
      "Training finished. Best val acc: 0.6325000000000001\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.0001 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 104\n",
      "Training finished. Best val acc: 0.6385000000000001\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.0001 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 90\n",
      "Training finished. Best val acc: 0.6335\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 0.0001 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 69\n",
      "Training finished. Best val acc: 0.6345000000000001\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 1e-07 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 74\n",
      "Training finished. Best val acc: 0.6455\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 1e-07 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 82\n",
      "Training finished. Best val acc: 0.6345000000000001\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 1e-07 MOM: 0 REG: 1e-05\n",
      "Early stopping at epoch: 82\n",
      "Training finished. Best val acc: 0.635\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 1e-07 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 79\n",
      "Training finished. Best val acc: 0.6335\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 1e-07 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 67\n",
      "Training finished. Best val acc: 0.633\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 1e-07 MOM: 0.5 REG: 1e-05\n",
      "Early stopping at epoch: 82\n",
      "Training finished. Best val acc: 0.631\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 1e-07 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 88\n",
      "Training finished. Best val acc: 0.6395\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 1e-07 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 70\n",
      "Training finished. Best val acc: 0.6234999999999999\n",
      "=========================================\n",
      "HID: [1024, 512] LR: 1e-07 MOM: 0.9 REG: 1e-05\n",
      "Early stopping at epoch: 70\n",
      "Training finished. Best val acc: 0.633\n",
      "=========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5782a82b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_dims = [ [512,256], [512,512], [1024,512] ]\n",
    "best_val_acc = 0.0\n",
    "best_two_model = None\n",
    "best_settings = {}\n",
    "\n",
    "for hd in hidden_dims:\n",
    "    for lr in learning_rates:\n",
    "        for mom in momentum:\n",
    "            for rg in regul:\n",
    "                print(\"HID:\",hd, \"LR:\", lr, \"MOM:\", mom, \"REG:\", rg)\n",
    "                two_model = FCNetwork(hidden_sizes=hd)\n",
    "                trained_model,best_val,tr_hist,val_hist = trainer.train(two_model, verbose=False, num_epochs=1000,\\\n",
    "                                                lr=lr, weight_decay=regul, momentum=mom, batch_size=64)\n",
    "\n",
    "                epochs=np.arange(len(tr_hist))\n",
    "                tr_hist = [min(tr_hist[i],700.0) for i in range(len(epochs))]\n",
    "                val_hist = [min(val_hist[i],700.0) for i in range(len(epochs))]\n",
    "                plt.plot(epochs, tr_hist, label=\"training error\")\n",
    "                plt.plot(epochs, val_hist, label=\"validation error\")\n",
    "                plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "                           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "                plt.savefig(\"HID:{0:}_LR={1:.1E}_MOM={2:.1E}_REG={3:.1E}.png\".format(str(hd),lr, mom, rg))\n",
    "                plt.clf()\n",
    "\n",
    "                if best_val > best_val_acc:\n",
    "                    best_val_acc = best_val\n",
    "                    best_two_model = trained_model\n",
    "                    best_settings.update( {\"HID\":hd, \"LR\":lr, \"MOM\": mom, \"REG\": rg } )\n",
    "                    torch.save(trained_model,\"HID:{0}_LR={1:.1E}_MOM={2:.1E}_REG={3:.1E}.pt\".format(str(hd),lr,mom,rg))\n",
    "                print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_settings: {'HID': [512, 512], 'LR': 1e-07, 'MOM': 0.5, 'REG': 0.1}\n",
      "best accuracy for one hidden layer: 0.646\n"
     ]
    }
   ],
   "source": [
    "acc, out=trainer.evaluate(best_two_model)\n",
    "print(\"best_settings:\", best_settings)\n",
    "print(\"best accuracy for one hidden layer:\",acc)\n",
    "np.save( \"best_two_estimations.npy\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HID: [512, 256, 256] LR: 0.01 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 85\n",
      "Training finished. Best val acc: 0.629\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.01 MOM: 0 REG: 0.01\n",
      "Early stopping at epoch: 136\n",
      "Training finished. Best val acc: 0.641\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.01 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 123\n",
      "Training finished. Best val acc: 0.645\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.01 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 84\n",
      "Training finished. Best val acc: 0.6445000000000001\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.01 MOM: 0.5 REG: 0.01\n",
      "Early stopping at epoch: 99\n",
      "Training finished. Best val acc: 0.634\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.01 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 187\n",
      "Training finished. Best val acc: 0.6485000000000001\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.01 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 175\n",
      "Training finished. Best val acc: 0.646\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.01 MOM: 0.9 REG: 0.01\n",
      "Early stopping at epoch: 124\n",
      "Training finished. Best val acc: 0.6395\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.01 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 87\n",
      "Training finished. Best val acc: 0.6305000000000001\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.0001 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 88\n",
      "Training finished. Best val acc: 0.6365000000000001\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.0001 MOM: 0 REG: 0.01\n",
      "Early stopping at epoch: 88\n",
      "Training finished. Best val acc: 0.632\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.0001 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 93\n",
      "Training finished. Best val acc: 0.6335\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.0001 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 69\n",
      "Training finished. Best val acc: 0.532\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.0001 MOM: 0.5 REG: 0.01\n",
      "Early stopping at epoch: 126\n",
      "Training finished. Best val acc: 0.644\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.0001 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 107\n",
      "Training finished. Best val acc: 0.6405000000000001\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.0001 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 91\n",
      "Training finished. Best val acc: 0.6335\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.0001 MOM: 0.9 REG: 0.01\n",
      "Early stopping at epoch: 77\n",
      "Training finished. Best val acc: 0.636\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 0.0001 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 142\n",
      "Training finished. Best val acc: 0.644\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-05 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 128\n",
      "Training finished. Best val acc: 0.646\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-05 MOM: 0 REG: 0.01\n",
      "Early stopping at epoch: 79\n",
      "Training finished. Best val acc: 0.629\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-05 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 115\n",
      "Training finished. Best val acc: 0.6385000000000001\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-05 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 119\n",
      "Training finished. Best val acc: 0.644\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-05 MOM: 0.5 REG: 0.01\n",
      "Early stopping at epoch: 151\n",
      "Training finished. Best val acc: 0.644\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-05 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 112\n",
      "Training finished. Best val acc: 0.6385000000000001\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-05 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 73\n",
      "Training finished. Best val acc: 0.641\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-05 MOM: 0.9 REG: 0.01\n",
      "Early stopping at epoch: 151\n",
      "Training finished. Best val acc: 0.643\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-05 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 100\n",
      "Training finished. Best val acc: 0.642\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-07 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 93\n",
      "Training finished. Best val acc: 0.65\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-07 MOM: 0 REG: 0.01\n",
      "Early stopping at epoch: 76\n",
      "Training finished. Best val acc: 0.6405000000000001\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-07 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 98\n",
      "Training finished. Best val acc: 0.64\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-07 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 150\n",
      "Training finished. Best val acc: 0.6435\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-07 MOM: 0.5 REG: 0.01\n",
      "Early stopping at epoch: 101\n",
      "Training finished. Best val acc: 0.6345000000000001\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-07 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 127\n",
      "Training finished. Best val acc: 0.644\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-07 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 137\n",
      "Training finished. Best val acc: 0.64\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-07 MOM: 0.9 REG: 0.01\n",
      "Early stopping at epoch: 129\n",
      "Training finished. Best val acc: 0.6435\n",
      "=========================================\n",
      "HID: [512, 256, 256] LR: 1e-07 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 98\n",
      "Training finished. Best val acc: 0.6505000000000001\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.01 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 80\n",
      "Training finished. Best val acc: 0.6355\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.01 MOM: 0 REG: 0.01\n",
      "Early stopping at epoch: 109\n",
      "Training finished. Best val acc: 0.6325000000000001\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.01 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 57\n",
      "Training finished. Best val acc: 0.6285000000000001\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.01 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 83\n",
      "Training finished. Best val acc: 0.64\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.01 MOM: 0.5 REG: 0.01\n",
      "Early stopping at epoch: 117\n",
      "Training finished. Best val acc: 0.642\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.01 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 61\n",
      "Training finished. Best val acc: 0.635\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.01 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 65\n",
      "Training finished. Best val acc: 0.6455\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.01 MOM: 0.9 REG: 0.01\n",
      "Early stopping at epoch: 71\n",
      "Training finished. Best val acc: 0.6365000000000001\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.01 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 106\n",
      "Training finished. Best val acc: 0.646\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.0001 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 62\n",
      "Training finished. Best val acc: 0.635\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.0001 MOM: 0 REG: 0.01\n",
      "Early stopping at epoch: 134\n",
      "Training finished. Best val acc: 0.646\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.0001 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 96\n",
      "Training finished. Best val acc: 0.651\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.0001 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 84\n",
      "Training finished. Best val acc: 0.6335\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.0001 MOM: 0.5 REG: 0.01\n",
      "Early stopping at epoch: 104\n",
      "Training finished. Best val acc: 0.6335\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.0001 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 72\n",
      "Training finished. Best val acc: 0.633\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.0001 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 56\n",
      "Training finished. Best val acc: 0.6285000000000001\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.0001 MOM: 0.9 REG: 0.01\n",
      "Early stopping at epoch: 63\n",
      "Training finished. Best val acc: 0.6355\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 0.0001 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 50\n",
      "Training finished. Best val acc: 0.6285000000000001\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-05 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 155\n",
      "Training finished. Best val acc: 0.643\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-05 MOM: 0 REG: 0.01\n",
      "Early stopping at epoch: 77\n",
      "Training finished. Best val acc: 0.6315\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-05 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 90\n",
      "Training finished. Best val acc: 0.65\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-05 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 65\n",
      "Training finished. Best val acc: 0.6315\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-05 MOM: 0.5 REG: 0.01\n",
      "Early stopping at epoch: 64\n",
      "Training finished. Best val acc: 0.6385000000000001\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-05 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 89\n",
      "Training finished. Best val acc: 0.635\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-05 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 95\n",
      "Training finished. Best val acc: 0.6275\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-05 MOM: 0.9 REG: 0.01\n",
      "Early stopping at epoch: 114\n",
      "Training finished. Best val acc: 0.6485000000000001\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-05 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 55\n",
      "Training finished. Best val acc: 0.626\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-07 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 100\n",
      "Training finished. Best val acc: 0.637\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-07 MOM: 0 REG: 0.01\n",
      "Early stopping at epoch: 154\n",
      "Training finished. Best val acc: 0.6425000000000001\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-07 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 86\n",
      "Training finished. Best val acc: 0.6375\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-07 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 45\n",
      "Training finished. Best val acc: 0.6234999999999999\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-07 MOM: 0.5 REG: 0.01\n",
      "Early stopping at epoch: 88\n",
      "Training finished. Best val acc: 0.631\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-07 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 92\n",
      "Training finished. Best val acc: 0.6305000000000001\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-07 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 58\n",
      "Training finished. Best val acc: 0.632\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-07 MOM: 0.9 REG: 0.01\n",
      "Early stopping at epoch: 95\n",
      "Training finished. Best val acc: 0.6385000000000001\n",
      "=========================================\n",
      "HID: [1024, 512, 256] LR: 1e-07 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 55\n",
      "Training finished. Best val acc: 0.6415\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.01 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 97\n",
      "Training finished. Best val acc: 0.6395\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.01 MOM: 0 REG: 0.01\n",
      "Early stopping at epoch: 128\n",
      "Training finished. Best val acc: 0.6415\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.01 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 108\n",
      "Training finished. Best val acc: 0.6385000000000001\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.01 MOM: 0.5 REG: 0.1\n",
      "Early stopping at epoch: 125\n",
      "Training finished. Best val acc: 0.6415\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.01 MOM: 0.5 REG: 0.01\n",
      "Early stopping at epoch: 102\n",
      "Training finished. Best val acc: 0.637\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.01 MOM: 0.5 REG: 0.001\n",
      "Early stopping at epoch: 110\n",
      "Training finished. Best val acc: 0.633\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.01 MOM: 0.9 REG: 0.1\n",
      "Early stopping at epoch: 186\n",
      "Training finished. Best val acc: 0.6455\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.01 MOM: 0.9 REG: 0.01\n",
      "Early stopping at epoch: 78\n",
      "Training finished. Best val acc: 0.6275\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.01 MOM: 0.9 REG: 0.001\n",
      "Early stopping at epoch: 123\n",
      "Training finished. Best val acc: 0.636\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.0001 MOM: 0 REG: 0.1\n",
      "Early stopping at epoch: 115\n",
      "Training finished. Best val acc: 0.6255\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.0001 MOM: 0 REG: 0.01\n",
      "Early stopping at epoch: 81\n",
      "Training finished. Best val acc: 0.6325000000000001\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.0001 MOM: 0 REG: 0.001\n",
      "Early stopping at epoch: 80\n",
      "Training finished. Best val acc: 0.6345000000000001\n",
      "=========================================\n",
      "HID: [1024, 1024, 512] LR: 0.0001 MOM: 0.5 REG: 0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-698e4a34fe67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HID:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LR:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MOM:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"REG:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mthree_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFCNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_hist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthree_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m                                                \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vision/the2/network.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, batch_size, num_epochs, verbose, lr, alpha, eps, weight_decay, momentum, long_history)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# One backward pass and parameter updates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f42dc730b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_dims = [ [512,256,256], [1024,512,256], [1024,1024,512] ]\n",
    "best_val_acc = 0.0\n",
    "learning_rates =[1e-2, 1e-4, 1e-5, 1e-7 ]\n",
    "regul = [0.1, 1e-2, 1e-3]\n",
    "best_three_model = None\n",
    "best_settings = {}\n",
    "\n",
    "\n",
    "for hd in hidden_dims:\n",
    "    for lr in learning_rates:\n",
    "        for mom in momentum:\n",
    "            for rg in regul:\n",
    "                print(\"HID:\",hd, \"LR:\", lr, \"MOM:\", mom, \"REG:\", rg)\n",
    "                three_model = FCNetwork(hidden_sizes=hd)\n",
    "                trained_model,best_val,tr_hist,val_hist = trainer.train(three_model, verbose=False, num_epochs=1000,\\\n",
    "                                                lr=lr, weight_decay=regul, momentum=mom, batch_size=64)\n",
    "\n",
    "                epochs=np.arange(len(tr_hist))\n",
    "                tr_hist = [min(tr_hist[i],700.0) for i in range(len(epochs))]\n",
    "                val_hist = [min(val_hist[i],700.0) for i in range(len(epochs))]\n",
    "                plt.plot(epochs, tr_hist, label=\"training error\")\n",
    "                plt.plot(epochs, val_hist, label=\"validation error\")\n",
    "                plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "                           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "                plt.savefig(\"HID:{0:}_LR={1:.1E}_MOM={2:.1E}_REG={3:.1E}.png\".format(str(hd),lr, mom, rg))\n",
    "                plt.clf()\n",
    "\n",
    "                if best_val > best_val_acc:\n",
    "                    best_val_acc = best_val\n",
    "                    best_three_model = trained_model\n",
    "                    best_settings.update( {\"HID\":hd, \"LR\":lr, \"MOM\": mom, \"REG\": rg } )\n",
    "                    torch.save(trained_model,\"HID:{0}_LR={1:.1E}_MOM={2:.1E}_REG={3:.1E}.pt\".format(str(hd),lr,mom,rg))\n",
    "                print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_settings: HID:[1024, 512, 256] LR=1.0E-04 MOM=0.0E+00 REG=1.0E-03\n",
      "best accuracy for three hidden layer: 0.651\n"
     ]
    }
   ],
   "source": [
    "best_three_model = torch.load(\"HID:[1024, 512, 256]_LR=1.0E-04_MOM=0.0E+00_REG=1.0E-03.pt\")\n",
    "acc, out=trainer.evaluate(best_three_model)\n",
    "print(\"best_settings: HID:[1024, 512, 256] LR=1.0E-04 MOM=0.0E+00 REG=1.0E-03\")\n",
    "print(\"best accuracy for three hidden layer:\", acc)\n",
    "np.save( \"best_three_estimations.npy\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Portrait Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_mavi = Trainer(val_path=\"samet_seksi.jpg_features.npy\", val_gt_path=\"me_gt.npy\")\n",
    "trainer_smt = Trainer(val_path=\"me_smt.jpg_features.npy\", val_gt_path=\"me_gt.npy\")\n",
    "trainer_ct = Trainer(val_path=\"me_ct.jpg_features.npy\", val_gt_path=\"me_gt.npy\")\n",
    "trainer_utk = Trainer(val_path=\"me_utk.jpg_features.npy\", val_gt_path=\"me_gt.npy\")\n",
    "trainer_wc = Trainer(val_path=\"me_wc.jpg_features.npy\", val_gt_path=\"me_gt.npy\")\n",
    "trainer_venice = Trainer(val_path=\"me_venice.jpg_features.npy\", val_gt_path=\"me_gt.npy\")\n",
    "trainer_florence = Trainer(val_path=\"me_florence.jpg_features.npy\", val_gt_path=\"me_gt.npy\")\n",
    "trainer_paris = Trainer(val_path=\"me_paris.jpg_features.npy\", val_gt_path=\"me_gt.npy\")\n",
    "trainer_talha = Trainer(val_path=\"talha.jpg_features.npy\", val_gt_path=\"me_gt.npy\")\n",
    "best_three_model = torch.load(\"HID:[1024, 512, 256]_LR=1.0E-04_MOM=0.0E+00_REG=1.0E-03.pt\")\n",
    "\n",
    "acc_mavi, _, out_mavi= trainer_mavi.evaluate(best_three_model)\n",
    "acc_smt,_, out_smt= trainer_smt.evaluate(best_three_model)\n",
    "acc_ct,_, out_ct= trainer_ct.evaluate(best_three_model)\n",
    "acc_utk,_, out_utk= trainer_utk.evaluate(best_three_model)\n",
    "acc_wc, _,out_wc= trainer_wc.evaluate(best_three_model)\n",
    "acc_venice,_, out_venice= trainer_venice.evaluate(best_three_model)\n",
    "acc_florence, _,out_florence= trainer_florence.evaluate(best_three_model)\n",
    "acc_paris,_, out_paris= trainer_paris.evaluate(best_three_model)\n",
    "\n",
    "acc_t, _,out_t= trainer_talha.evaluate(best_three_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mavi guess: [[26.459087]]\n",
      "smt guess: [[37.478764]]\n",
      "ct guess: [[44.3543]]\n",
      "utk guess: [[33.87099]]\n",
      "wc guess: [[55.756905]]\n",
      "venice guess: [[33.563778]]\n",
      "florence guess: [[31.016302]]\n",
      "paris guess: [[28.227682]]\n",
      "talha guess: [[25.035347]]\n"
     ]
    }
   ],
   "source": [
    "print(\"mavi guess:\",out_mavi)\n",
    "print(\"smt guess:\",out_smt)\n",
    "print(\"ct guess:\",out_ct)\n",
    "print(\"utk guess:\",out_utk)\n",
    "print(\"wc guess:\",out_wc)\n",
    "print(\"venice guess:\",out_venice)\n",
    "print(\"florence guess:\",out_florence)\n",
    "print(\"paris guess:\",out_paris)\n",
    "print(\"talha guess:\",out_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_two_model = torch.load(\"HID:[512, 512]_LR=1.0E-04_MOM=0.0E+00_REG=1.0E-03.pt\")\n",
    "\n",
    "acc_mavi, _,out_mavi= trainer_mavi.evaluate(best_two_model)\n",
    "acc_smt,_, out_smt= trainer_smt.evaluate(best_two_model)\n",
    "acc_ct, _,out_ct= trainer_ct.evaluate(best_two_model)\n",
    "acc_utk, _,out_utk= trainer_utk.evaluate(best_two_model)\n",
    "acc_wc,_, out_wc= trainer_wc.evaluate(best_two_model)\n",
    "acc_venice,_, out_venice= trainer_venice.evaluate(best_two_model)\n",
    "acc_florence, _,out_florence= trainer_florence.evaluate(best_two_model)\n",
    "acc_paris, _,out_paris= trainer_paris.evaluate(best_two_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mavi guess: [[25.967703]]\n",
      "smt guess: [[35.535748]]\n",
      "ct guess: [[43.223312]]\n",
      "utk guess: [[36.958897]]\n",
      "wc guess: [[50.35201]]\n",
      "venice guess: [[45.191757]]\n",
      "florence guess: [[30.69101]]\n",
      "paris guess: [[27.385012]]\n"
     ]
    }
   ],
   "source": [
    "print(\"mavi guess:\",out_mavi)\n",
    "print(\"smt guess:\",out_smt)\n",
    "print(\"ct guess:\",out_ct)\n",
    "print(\"utk guess:\",out_utk)\n",
    "print(\"wc guess:\",out_wc)\n",
    "print(\"venice guess:\",out_venice)\n",
    "print(\"florence guess:\",out_florence)\n",
    "print(\"paris guess:\",out_paris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_one_model = torch.load(\"HID:[1024]_LR=1.0E-07_MOM=5.0E-01_REG=1.0E-01.pt\")\n",
    "\n",
    "acc_mavi,_, out_mavi= trainer_mavi.evaluate(best_one_model)\n",
    "acc_smt, _,out_smt= trainer_smt.evaluate(best_one_model)\n",
    "acc_ct,_, out_ct= trainer_ct.evaluate(best_one_model)\n",
    "acc_utk,_, out_utk= trainer_utk.evaluate(best_one_model)\n",
    "acc_wc,_, out_wc= trainer_wc.evaluate(best_one_model)\n",
    "acc_venice, _,out_venice= trainer_venice.evaluate(best_one_model)\n",
    "acc_florence, _,out_florence= trainer_florence.evaluate(best_one_model)\n",
    "acc_paris,_, out_paris= trainer_paris.evaluate(best_one_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mavi guess: [[28.831446]]\n",
      "smt guess: [[41.24435]]\n",
      "ct guess: [[39.676533]]\n",
      "utk guess: [[34.621452]]\n",
      "wc guess: [[46.33735]]\n",
      "venice guess: [[43.285732]]\n",
      "florence guess: [[30.88027]]\n",
      "paris guess: [[28.037645]]\n"
     ]
    }
   ],
   "source": [
    "print(\"mavi guess:\",out_mavi)\n",
    "print(\"smt guess:\",out_smt)\n",
    "print(\"ct guess:\",out_ct)\n",
    "print(\"utk guess:\",out_utk)\n",
    "print(\"wc guess:\",out_wc)\n",
    "print(\"venice guess:\",out_venice)\n",
    "print(\"florence guess:\",out_florence)\n",
    "print(\"paris guess:\",out_paris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6445000000000001 0.643 0.646 0.6425000000000001 0.651 0.6505000000000001\n",
      "162.89105224609375 164.157958984375 172.26390075683594 165.76470947265625 175.85845947265625 170.79318237304688\n",
      "12.762877898267842 13.124934314381765 13.261163579138003 13.068786568501563\n",
      "[[49.949318]] [[35.842144]] [[47.490757]] [[30.958305]]\n"
     ]
    }
   ],
   "source": [
    "best_one_model = torch.load(\"HID:[1024]_LR=1.0E-07_MOM=5.0E-01_REG=1.0E-01.pt\")\n",
    "best_two_model = torch.load(\"HID:[512, 512]_LR=1.0E-07_MOM=5.0E-01_REG=1.0E-01.pt\")\n",
    "best_two_model2 = torch.load(\"HID:[512, 512]_LR=1.0E-04_MOM=0.0E+00_REG=1.0E-03.pt\")\n",
    "best_three_model = torch.load(\"HID:[1024, 512, 256]_LR=1.0E-04_MOM=0.0E+00_REG=1.0E-03.pt\")\n",
    "three2 = torch.load(\"HID:[512, 256, 256]_LR=1.0E-07_MOM=9.0E-01_REG=1.0E-03.pt\")\n",
    "one2 = torch.load(\"HID:[512]_LR=1.0E-04_MOM=0.0E+00_REG=1.0E-05.pt\")\n",
    "\n",
    "\n",
    "acc1, val1, _ = trainer.evaluate(best_one_model)\n",
    "acc12, val12, _ = trainer.evaluate(one2)\n",
    "acc2, val2, _ = trainer.evaluate(best_two_model)\n",
    "acc22, val22, _ = trainer.evaluate(best_two_model2)\n",
    "acc3, val3, _ = trainer.evaluate(best_three_model)\n",
    "accd, vald, _ = trainer.evaluate(three2)\n",
    "print(acc1,acc12, acc2, acc22,acc3,accd)\n",
    "print(val1, val12, val2, val22, val3,vald)\n",
    "print(pow(val1,0.5),pow(val2,0.5),pow(val3,0.5),pow(vald,0.5))\n",
    "\n",
    "\n",
    "acc_wc,_, out_wc= trainer_wc.evaluate(best_two_model)\n",
    "acc_u,_, out_u= trainer_utk.evaluate(best_two_model)\n",
    "acc_v,_, out_v= trainer_venice.evaluate(best_two_model)\n",
    "acc_p,_, out_p= trainer_paris.evaluate(best_two_model)\n",
    "\n",
    "\n",
    "print(out_wc, out_u, out_v, out_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 212.9920, Val Loss: 195.2254\n",
      "improved accuracy\n",
      "improved val loss\n",
      "Epoch [2/1000], Loss: 188.9158, Val Loss: 184.3088\n",
      "improved val loss\n",
      "Epoch [3/1000], Loss: 268.6698, Val Loss: 302.7520\n",
      "Epoch [4/1000], Loss: 373.6212, Val Loss: 212.0916\n",
      "Epoch [5/1000], Loss: 216.0958, Val Loss: 292.8442\n",
      "Epoch [6/1000], Loss: 63.1116, Val Loss: 207.8641\n",
      "improved val loss\n",
      "Epoch [7/1000], Loss: 98.3969, Val Loss: 180.6000\n",
      "improved val loss\n",
      "Epoch [8/1000], Loss: 111.5225, Val Loss: 182.1071\n",
      "improved accuracy\n",
      "improved val loss\n",
      "Epoch [9/1000], Loss: 157.6444, Val Loss: 211.6874\n",
      "improved accuracy\n",
      "Epoch [10/1000], Loss: 62.9569, Val Loss: 173.5913\n",
      "improved val loss\n",
      "Epoch [11/1000], Loss: 101.0675, Val Loss: 209.1259\n",
      "Epoch [12/1000], Loss: 94.0322, Val Loss: 192.3550\n",
      "Epoch [13/1000], Loss: 173.8636, Val Loss: 177.4702\n",
      "Epoch [14/1000], Loss: 142.5617, Val Loss: 270.8109\n",
      "Epoch [15/1000], Loss: 46.8913, Val Loss: 167.5475\n",
      "Epoch [16/1000], Loss: 176.4882, Val Loss: 149.4722\n",
      "Epoch [17/1000], Loss: 203.9941, Val Loss: 241.5675\n",
      "Epoch [18/1000], Loss: 109.6217, Val Loss: 227.1837\n",
      "Epoch [19/1000], Loss: 164.0869, Val Loss: 169.0106\n",
      "improved val loss\n",
      "Epoch [20/1000], Loss: 44.8064, Val Loss: 174.5685\n",
      "Epoch [21/1000], Loss: 62.0465, Val Loss: 178.0068\n",
      "Epoch [22/1000], Loss: 314.0844, Val Loss: 230.8647\n",
      "Epoch [23/1000], Loss: 91.4724, Val Loss: 168.1464\n",
      "improved val loss\n",
      "Epoch [24/1000], Loss: 148.8078, Val Loss: 154.4378\n",
      "Epoch [25/1000], Loss: 67.5626, Val Loss: 171.6398\n",
      "Epoch [26/1000], Loss: 149.3140, Val Loss: 185.4683\n",
      "Epoch [27/1000], Loss: 109.9653, Val Loss: 211.8015\n",
      "Epoch [28/1000], Loss: 173.0408, Val Loss: 194.7850\n",
      "Epoch [29/1000], Loss: 120.7650, Val Loss: 162.1278\n",
      "improved val loss\n",
      "Epoch [30/1000], Loss: 90.5439, Val Loss: 189.6859\n",
      "Epoch [31/1000], Loss: 230.6582, Val Loss: 197.9046\n",
      "Epoch [32/1000], Loss: 153.6814, Val Loss: 235.1362\n",
      "Epoch [33/1000], Loss: 101.1522, Val Loss: 183.6311\n",
      "Epoch [34/1000], Loss: 127.1983, Val Loss: 210.3729\n",
      "Epoch [35/1000], Loss: 228.4346, Val Loss: 206.5503\n",
      "Epoch [36/1000], Loss: 178.9785, Val Loss: 169.7271\n",
      "Epoch [37/1000], Loss: 76.0808, Val Loss: 206.9357\n",
      "Epoch [38/1000], Loss: 90.0462, Val Loss: 164.9689\n",
      "improved val loss\n",
      "Epoch [39/1000], Loss: 184.5090, Val Loss: 235.2868\n",
      "Epoch [40/1000], Loss: 54.7858, Val Loss: 165.7877\n",
      "Epoch [41/1000], Loss: 72.2473, Val Loss: 177.0054\n",
      "Epoch [42/1000], Loss: 100.1410, Val Loss: 169.6520\n",
      "improved val loss\n",
      "Epoch [43/1000], Loss: 86.9776, Val Loss: 184.9490\n",
      "Epoch [44/1000], Loss: 364.2377, Val Loss: 253.2036\n",
      "Epoch [45/1000], Loss: 98.9588, Val Loss: 248.5096\n",
      "Epoch [46/1000], Loss: 166.7746, Val Loss: 190.4309\n",
      "Epoch [47/1000], Loss: 137.6164, Val Loss: 211.4458\n",
      "Epoch [48/1000], Loss: 103.5666, Val Loss: 171.3743\n",
      "Epoch [49/1000], Loss: 115.5212, Val Loss: 266.1352\n",
      "Epoch [50/1000], Loss: 153.4709, Val Loss: 214.2825\n",
      "Epoch [51/1000], Loss: 46.1307, Val Loss: 157.8528\n",
      "Epoch [52/1000], Loss: 72.6647, Val Loss: 216.6883\n",
      "Epoch [53/1000], Loss: 121.8011, Val Loss: 159.2958\n",
      "Epoch [54/1000], Loss: 81.0735, Val Loss: 184.1381\n",
      "Epoch [55/1000], Loss: 329.3021, Val Loss: 203.2436\n",
      "Epoch [56/1000], Loss: 121.8734, Val Loss: 228.5466\n",
      "Epoch [57/1000], Loss: 87.1178, Val Loss: 188.6910\n",
      "Epoch [58/1000], Loss: 80.6941, Val Loss: 181.2918\n",
      "Epoch [59/1000], Loss: 60.2605, Val Loss: 184.0475\n",
      "Epoch [60/1000], Loss: 162.5545, Val Loss: 298.6305\n",
      "Epoch [61/1000], Loss: 235.7552, Val Loss: 224.5946\n",
      "Epoch [62/1000], Loss: 78.9509, Val Loss: 145.1428\n",
      "Epoch [63/1000], Loss: 136.2304, Val Loss: 239.1992\n",
      "Epoch [64/1000], Loss: 110.2875, Val Loss: 195.4302\n",
      "Epoch [65/1000], Loss: 205.6850, Val Loss: 189.6798\n",
      "improved val loss\n",
      "Epoch [66/1000], Loss: 96.3295, Val Loss: 154.0784\n",
      "Epoch [67/1000], Loss: 112.7917, Val Loss: 299.7961\n",
      "Epoch [68/1000], Loss: 298.8144, Val Loss: 325.2927\n",
      "Epoch [69/1000], Loss: 157.7794, Val Loss: 212.9865\n",
      "Epoch [70/1000], Loss: 346.6685, Val Loss: 291.9869\n",
      "Epoch [71/1000], Loss: 132.9820, Val Loss: 174.8826\n",
      "Epoch [72/1000], Loss: 128.2056, Val Loss: 225.1577\n",
      "Epoch [73/1000], Loss: 158.1581, Val Loss: 175.1536\n",
      "Epoch [74/1000], Loss: 325.7239, Val Loss: 397.9247\n",
      "Epoch [75/1000], Loss: 180.8731, Val Loss: 365.5431\n",
      "Epoch [76/1000], Loss: 105.4470, Val Loss: 179.4150\n",
      "Epoch [77/1000], Loss: 165.4427, Val Loss: 169.6460\n",
      "Epoch [78/1000], Loss: 145.5945, Val Loss: 222.3616\n",
      "Epoch [79/1000], Loss: 176.9360, Val Loss: 185.1892\n",
      "Epoch [80/1000], Loss: 112.6582, Val Loss: 172.0270\n",
      "Epoch [81/1000], Loss: 60.6646, Val Loss: 162.3679\n",
      "Epoch [82/1000], Loss: 64.8573, Val Loss: 226.5106\n",
      "Epoch [83/1000], Loss: 129.4448, Val Loss: 199.5457\n",
      "Epoch [84/1000], Loss: 126.8319, Val Loss: 229.5218\n",
      "Epoch [85/1000], Loss: 149.2572, Val Loss: 198.3483\n",
      "Epoch [86/1000], Loss: 127.1869, Val Loss: 284.0369\n",
      "Epoch [87/1000], Loss: 37.0320, Val Loss: 180.8938\n",
      "Epoch [88/1000], Loss: 339.4622, Val Loss: 155.6591\n",
      "Epoch [89/1000], Loss: 99.4039, Val Loss: 201.7005\n",
      "Epoch [90/1000], Loss: 129.2021, Val Loss: 181.6574\n",
      "Epoch [91/1000], Loss: 157.1394, Val Loss: 170.3670\n",
      "Epoch [92/1000], Loss: 75.4862, Val Loss: 159.1306\n",
      "Epoch [93/1000], Loss: 53.1242, Val Loss: 170.6052\n",
      "improved val loss\n",
      "Epoch [94/1000], Loss: 254.0706, Val Loss: 169.5905\n",
      "Epoch [95/1000], Loss: 257.0894, Val Loss: 181.8012\n",
      "Epoch [96/1000], Loss: 64.2209, Val Loss: 176.1430\n",
      "Epoch [97/1000], Loss: 108.7770, Val Loss: 214.4421\n",
      "Epoch [98/1000], Loss: 64.6686, Val Loss: 165.9849\n",
      "improved val loss\n",
      "Epoch [99/1000], Loss: 77.3047, Val Loss: 163.7956\n",
      "Epoch [100/1000], Loss: 109.7652, Val Loss: 197.5755\n",
      "Epoch [101/1000], Loss: 149.4636, Val Loss: 164.7024\n",
      "Epoch [102/1000], Loss: 185.1261, Val Loss: 190.4854\n",
      "Epoch [103/1000], Loss: 134.8231, Val Loss: 217.0313\n",
      "Epoch [104/1000], Loss: 87.0558, Val Loss: 175.5774\n",
      "Epoch [105/1000], Loss: 173.8952, Val Loss: 176.4923\n",
      "Epoch [106/1000], Loss: 223.2363, Val Loss: 276.1019\n",
      "Epoch [107/1000], Loss: 116.5070, Val Loss: 176.8012\n",
      "Epoch [108/1000], Loss: 30.1473, Val Loss: 162.3364\n",
      "Epoch [109/1000], Loss: 186.1722, Val Loss: 183.3937\n",
      "Epoch [110/1000], Loss: 31.9297, Val Loss: 194.1275\n",
      "Epoch [111/1000], Loss: 280.3360, Val Loss: 174.7689\n",
      "Epoch [112/1000], Loss: 116.1172, Val Loss: 193.0740\n",
      "Epoch [113/1000], Loss: 52.3639, Val Loss: 274.9903\n",
      "Epoch [114/1000], Loss: 56.4589, Val Loss: 167.8970\n",
      "Epoch [115/1000], Loss: 156.8033, Val Loss: 157.6839\n",
      "Epoch [116/1000], Loss: 205.6722, Val Loss: 273.2170\n",
      "Epoch [117/1000], Loss: 68.5989, Val Loss: 203.0689\n",
      "Epoch [118/1000], Loss: 84.2779, Val Loss: 269.9633\n",
      "Epoch [119/1000], Loss: 206.9599, Val Loss: 173.3576\n",
      "Epoch [120/1000], Loss: 49.0809, Val Loss: 179.9589\n",
      "Epoch [121/1000], Loss: 116.8855, Val Loss: 205.7693\n",
      "Epoch [122/1000], Loss: 84.4619, Val Loss: 178.3386\n",
      "Epoch [123/1000], Loss: 169.5241, Val Loss: 169.5835\n",
      "Epoch [124/1000], Loss: 186.9288, Val Loss: 180.5165\n",
      "Epoch [125/1000], Loss: 93.3058, Val Loss: 201.9806\n",
      "Epoch [126/1000], Loss: 118.8069, Val Loss: 170.4696\n",
      "Epoch [127/1000], Loss: 173.0149, Val Loss: 173.4486\n",
      "Epoch [128/1000], Loss: 229.7692, Val Loss: 192.0026\n",
      "Early stopping at epoch: 128\n",
      "Training finished. Best val acc: 0.591\n"
     ]
    }
   ],
   "source": [
    "extra_model = FCNetwork(hidden_sizes=[])\n",
    "trained_model,best_val,tr_hist,val_hist = trainer.train(extra_model, verbose=True, num_epochs=1000,\\\n",
    "                                                lr=1e-4, weight_decay=1e-5, momentum=0, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=np.arange(len(tr_hist))\n",
    "tr_hist = [min(tr_hist[i].data[0],700.0) for i in range(len(epochs))]\n",
    "val_hist = [min(val_hist[i],700.0) for i in range(len(epochs))]\n",
    "plt.plot(epochs, tr_hist, label=\"training error\")\n",
    "plt.plot(epochs, val_hist, label=\"validation error\")\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig(\"last.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainer = Trainer()\n",
    "best_three = torch.load(\"HID:[512, 256, 256]_LR=1.0E-07_MOM=9.0E-01_REG=1.0E-03.pt\")\n",
    "test_out = trainer.evaluate(best_three, \"test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test_out.npy\", test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
